{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kaggle - Titanic - Survival prediction\n",
    "## [1. Reading train and test data](#Reading_data)\n",
    "## [2. Exploration of the data](#Data_exploration)\n",
    "## [3. Feature engineering (I) - Filling the NaNs](#Feature_engineering_1)\n",
    "## [4. Prediction models (I)](#Prediction_models_1)\n",
    "## [5. Feature engineering (II)](#Feature_engineering_2)\n",
    "> ### [5.1 Playing with: 'Name'](#FE2_name)\n",
    "> ### [5.2 Playing with: 'Age'](#FE2_Age)\n",
    "> ### [5.3 Playing with: 'Embarked'](#FE2_embarked)\n",
    "> ### [5.4 Playing with: 'Fare'](#FE2_fare)\n",
    "> ### [5.5 Playing with: 'Ticket'](#FE2_ticket)\n",
    "> ### [5.6 Playing with: 'Sibsp' and 'Parch'](#FE2_sibsp)\n",
    "\n",
    "## [6. Prediction models (II)](#Prediction_models_2)\n",
    "\n",
    "<a id=\"Reading_data\"></a> \n",
    "# 1. Reading train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set() # Plot style\n",
    "\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "IPython.core.pylabtools.figsize(12, 4)\n",
    "\n",
    "# Import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open CSV file for train data and test data\n",
    "df = []\n",
    "df.append(pd.read_csv('data/train.csv'))\n",
    "df.append(pd.read_csv('data/test.csv'))\n",
    "\n",
    "# Create two different pointers to the train and the test data\n",
    "df_train = df[0]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df[1]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combined = df[0].append(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print df_train.shape\n",
    "#print combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Data_exploration\"></a>\n",
    "# 2. Exploration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Analysis of null in training dataset'\n",
    "print '-----------------------------------'\n",
    "print 'Passenger_id nulls: ' + str(df_train['PassengerId'].isnull().sum())\n",
    "print 'Pclass nulls: ' + str(df_train['Pclass'].isnull().sum())\n",
    "print 'Age nulls: ' + str(df_train['Age'].isnull().sum())\n",
    "print 'SibSp nulls: ' + str(df_train['SibSp'].isnull().sum())\n",
    "print 'Parch nulls: ' + str(df_train['Parch'].isnull().sum())\n",
    "print 'Ticket nulls: ' + str(df_train['Ticket'].isnull().sum())\n",
    "print 'Fare nulls: ' + str(df_train['Fare'].isnull().sum())\n",
    "print 'Cabin nulls: ' + str(df_train['Cabin'].isnull().sum())\n",
    "print 'Embarked nulls: ' + str(df_train['Embarked'].isnull().sum())\n",
    "print '-----------------------------------'\n",
    "nan_rows = df_train[df_train['Age'].isnull()]\n",
    "nan_rows.loc[:,:].head()\n",
    "\n",
    "# Most frequent value per column\n",
    "print 'Mean/Median/Mode in training dataset per column'\n",
    "print '-----------------------------------'\n",
    "print 'Embarked:'\n",
    "print df_train['Embarked'].value_counts()\n",
    "\n",
    "print \"Fare: Mean = %f , Median = %f , Mode = %f\" % (df_train['Fare'].mean(),df_train['Fare'].median(),df_train['Fare'].mode())\n",
    "#print \"Fare: Mean = %f , Median = %f , Mode = %f\" % (df_train['Ticket'].mean(),df_train['Ticket'].median(),df_train['Ticket'].mode())\n",
    "print 'Ticket:'\n",
    "print df_train['Ticket'].value_counts().head()\n",
    "print \"Age: Mean = %f , Median = %f , Mode = %f\" % (df_train['Age'].mean(),df_train['Age'].median(),df_train['Age'].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "* Min(Fare) is 0. This could mean that there are babies (for example) free of charge, or actually errors.\n",
    "* We need to check the distribution of Fare prices, and decide whether making buckets or not.\n",
    "* There are 2 nulls in 'Embarked'. Replace NaN by 'S', by far the most repeated value.\n",
    "* Cabin nulls may mean people without a cabin, hence, there were less cabins than people.\n",
    "* Ticket is alphanumeric\n",
    "* We have five categorical variables: Sex, Embarked, Class, and Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Ratio of survival in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_passengers_train = df_train.shape[0]\n",
    "print 'Number of passengers: ' + str(num_passengers_train)\n",
    "\n",
    "#num_passengers_survived_train = df_train.groupby('Survived').size()[1]\n",
    "num_passengers_survived_train = df_train[df_train['Survived']==1].shape[0]\n",
    "print 'Number of survivors: ' + str(num_passengers_survived_train)\n",
    "\n",
    "ratio_survival = (num_passengers_survived_train/num_passengers_train)\n",
    "print 'Survival ratio in training data = ' + str(round(ratio_survival*100,2)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Men vs women survival ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break by men and women\n",
    "women_train = df_train[df_train['Sex']=='female']\n",
    "men_train = df_train[df_train['Sex']=='male']\n",
    "\n",
    "num_women_train = women_train.shape[0]\n",
    "num_men_train = men_train.shape[0]\n",
    "print 'Women on board: ' + str(num_women_train)\n",
    "print 'Men on board: ' + str(num_men_train)\n",
    "\n",
    "num_women_survived_train = women_train[women_train['Survived']==1].shape[0]\n",
    "num_men_survived_train = men_train[men_train['Survived']==1].shape[0]\n",
    "\n",
    "\n",
    "ratio_survival_women = (num_women_survived_train/num_women_train)\n",
    "ratio_survival_men = (num_men_survived_train/num_men_train)\n",
    "\n",
    "print 'Survival ratio for women in training data = ' + str(round(ratio_survival_women*100,2)) + \"%\"\n",
    "print 'Survival ratio for men in training data = ' + str(round(ratio_survival_men*100,2)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data Visualisation\n",
    "* Constrast different subsets of variables to hint correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Survived vs Pclass and Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First row\n",
    "# Survivors and classes\n",
    "fig, axs = plt.subplots(ncols=3)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_survived = sns.countplot('Survived', data=df_train, ax=axs[0])\n",
    "fig_pclass = sns.countplot('Pclass', data=df_train, ax=axs[1])\n",
    "fig_survived_per_class = sns.pointplot('Pclass', 'Survived', data=df_train, ax=axs[2])\n",
    "\n",
    "fig_survived_per_class.set(ylim=(0,1))\n",
    "fig_survived.set_title('Number of survivors')\n",
    "fig_pclass.set_title('People per class') \n",
    "fig_survived_per_class.set_title('% survival per class')\n",
    "\n",
    "# Second row\n",
    "# Proportion of survivors per class and sex\n",
    "fig, axs = plt.subplots(ncols=3)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_sex = sns.countplot('Sex', data=df_train, ax=axs[0])\n",
    "fig_survived_by_sex = sns.pointplot('Sex', 'Survived', data=df_train, ax=axs[1])\n",
    "fig_survived_by_sex_class = sns.pointplot('Pclass', 'Survived', data=df_train, hue='Sex', ax=axs[2])\n",
    "\n",
    "fig_sex.set_title('People per sex')\n",
    "fig_survived_by_sex.set_title('% survival per sex')\n",
    "fig_survived_by_sex.set(ylim=(0, 1.1))\n",
    "fig_survived_by_sex_class.set_title('% survival per sex & class')\n",
    "fig_survived_by_sex_class.set(ylim=(0, 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* The lower the class (3 is worst class than 1), the less the ratio of survival\n",
    "* Females have an incredible ratio of survival compare to male\n",
    "* \"Women and children first\" seems to be true. Check later the age to verify\n",
    "* Both Sex and Class seems very important for the survival ratio\n",
    "\n",
    "#### Actions\n",
    "* Sex and Class need to be included in the model\n",
    "* Check the real impact of these variables in the models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Survived vs embarkation point, class and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third row\n",
    "# Proportion of survivors per embarked. Class per embark point\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_embarked = sns.countplot('Embarked', data=df_train, ax=axs[0])\n",
    "fig_survived_by_embarked = sns.pointplot('Embarked', 'Survived', data=df_train, ax=axs[1])\n",
    "\n",
    "fig_embarked.set_title('People per port')\n",
    "fig_survived_by_embarked.set_title('% survival per port of embarkation')\n",
    "\n",
    "# Fourth row\n",
    "grid = sns.FacetGrid(df_train, col='Embarked', size=3.5, aspect=1)\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* The embarkation port seems to influence, specially in port C \n",
    "* Note that 'Male' survival is almost 100% for those who embarked from C, while female is signicantly lower!\n",
    "* Very low rate of survivals from port Q\n",
    "* Question: embarkation point could determine the cabin, and the location of the cabin in the Titanic could have been essential, depending on the point of impact with the iceberg\n",
    "\n",
    "#### Actions\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Survived vs Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of survived and dead by age\n",
    "g = sns.FacetGrid(df_train, col='Survived', size=4, aspect=1)\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#fig = sns.FacetGrid(df_train, hue='Pclass', size=3, aspect=3)\n",
    "#fig.map(sns.kdeplot, 'Fare', shade=True, legend=True)\n",
    "#fig.set(xlim=(0, 80));\n",
    "#fig.set(ylim=(0, 0.1));\n",
    "#fig.add_legend()\n",
    "\n",
    "# Distribution of age by class\n",
    "fig = sns.FacetGrid(df_train, hue='Pclass', size=3, aspect=3)\n",
    "fig.map(sns.kdeplot, 'Age', shade=True)\n",
    "fig.set(xlim=(0, 80));\n",
    "fig.set(ylim=(0, 0.1));\n",
    "fig.add_legend()\n",
    "\n",
    "# Median of Age per class\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_median_age_class = sns.barplot(data=df_train, x='Pclass', y='Age', estimator=np.median, ax=axs[0])\n",
    "fig_mean_age_class = sns.barplot(data=df_train, x='Pclass', y='Age', estimator=np.mean, ax=axs[1])\n",
    "\n",
    "fig_median_age_class.set_title('Median of Age per class')\n",
    "fig_mean_age_class.set_title('Mean of Age per class')\n",
    "\n",
    "print 'Median of Age for all classes: ' + str(df_train['Age'].median()) + ' years'\n",
    "print 'Median of Age for class 1: ' + str(df_train[df_train['Pclass']==1]['Age'].median()) + ' years'\n",
    "print 'Median of Age for class 2: ' + str(df_train[df_train['Pclass']==2]['Age'].median()) + ' years'\n",
    "print 'Median of Age for class 3: ' + str(df_train[df_train['Pclass']==3]['Age'].median()) + ' years'\n",
    "\n",
    "df_train[(df_train['Pclass']==3) & (df_train['Embarked']=='S')]\n",
    "g = sns.FacetGrid(df_train, col='Pclass', size=4, aspect=1)\n",
    "g.map(plt.hist, 'Age', bins = 20)\n",
    "\n",
    "#g = sns.FacetGrid(df_train, col='Embarked', size=4, aspect=1)\n",
    "#g.map(plt.hist, 'Age', bins = 20)\n",
    "\n",
    "# Age by class and embarkation point\n",
    "g = sns.FacetGrid(df_train, row='Embarked', col='Pclass', size=2, aspect=2, margin_titles=True)\n",
    "g.map(plt.hist, 'Age', bins = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many were not adults?\n",
    "print 'How many kids in the titanic (train dataset) (<16): ' + str(len(df_train[df_train['Age']<16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* There are a few children (<16). This could affect the survival ratio\n",
    "* Create buckets/bins for Age could be benefitial\n",
    "* Median/mean of age differs depending on the class. It makes senses, the older people would be wealthier\n",
    "#### Actions\n",
    "* Create a new variable 'Person' to distinguish between Woman, Man, and Child\n",
    "* Try creating a new variable 'Age_range' with 5-6 intervals\n",
    "* Fill NaN values in Age by taking the median per class (Consider embarkation point as well?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Cabin vs Survived\n",
    "* Understanding of Cabin codes, and how this could have affected the survival ratio (Titanic's sink was at night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Survived vs Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()\n",
    "print 'Fare nulls: ' + str(df_train['Fare'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Fare\n",
    "sns.distplot(df_train['Fare'].dropna(), kde=True, rug=False)\n",
    "plt.suptitle('Distribution of Fares')\n",
    "#sns.distplot(df_train['Pclass'=='1'], kde=True, rug=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Distribution of Fares by class')\n",
    "sns.distplot(df_train[df_train['Pclass']==3]['Fare'], kde=True, rug=False, ax=ax, label=\"Class 3\")\n",
    "sns.distplot(df_train[df_train['Pclass']==2]['Fare'], kde=True, rug=False, ax=ax, label=\"Class 2\")\n",
    "sns.distplot(df_train[df_train['Pclass']==1]['Fare'], kde=True, rug=False, ax=ax, label=\"Class 1\")\n",
    "plt.legend()\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,0.10])\n",
    "g = sns.FacetGrid(df_train, col='Pclass', size=4, aspect=1)\n",
    "g.map(plt.hist, 'Fare', bins = 20)\n",
    "\n",
    "\n",
    "#g = sns.FacetGrid(df_train, col='Survived', size=4, aspect=1)\n",
    "#g.map(plt.hist, 'Fare', bins=20)\n",
    "\n",
    "figure = plt.figure(figsize=(15,8))\n",
    "plt.hist([df_train[df_train['Survived']==1]['Fare'],df_train[df_train['Survived']==0]['Fare']], \n",
    "         stacked=True, color = ['g','r'],\n",
    "         bins = 20,label = ['Survived','Dead'])\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* Most of the people pay less than 40 for the ticket\n",
    "* The more someone paid, the better survival ratio. Those who paid more than 100, almost guaranteed their survival\n",
    "* Fare is very skewed.\n",
    "#### Actions\n",
    "* Create intervals for 'Fare'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Feature_engineering_1\"></a> \n",
    "# 3. Feature engineering (I) - Only basic stuff to be able to run our first model\n",
    "* Check if there are NaN values in certain columns, such as Embarked, and replace them by other values\n",
    "* Data imputation is done in both train and test datasets, but only taking information from the train dataset. This way we avoid to include information from the test dataset into the train one. We may get higher accuracy by also exploring the test dataset, but this is not a good practice\n",
    "* We will create new features for data imputation, so we can always go back and apply different transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embarked**: Replace NaN in embarked by 'S', by far the most repeated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Embarked'] = df_train['Embarked'].fillna('S')\n",
    "print 'Embarked nulls in train: ' + str(df_train['Embarked'].isnull().sum())\n",
    "\n",
    "df_test['Embarked'] = df_test['Embarked'].fillna('S')\n",
    "print 'Embarked nulls in test: ' + str(df_test['Embarked'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**: Replace NaN by median depending on the class and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median per class\n",
    "df_train['AgeFill'] = df_train['Age']\n",
    "df_test['AgeFill'] = df_test['Age']\n",
    "\n",
    "age_median_table = df_train.groupby(['Sex','Pclass'])['Age'].median()\n",
    "print age_median_table\n",
    "\n",
    "def fill_age_sex_class(x,base_table):\n",
    "    age = base_table.loc[x['Sex'], x['Pclass']]                 \n",
    "    return age\n",
    "\n",
    "df_train['AgeFill'] = df_train.apply(lambda x: fill_age_sex_class(x,age_median_table) if np.isnan(x['AgeFill']) else x['AgeFill'], axis=1)\n",
    "df_test['AgeFill'] = df_test.apply(lambda x: fill_age_sex_class(x,age_median_table) if np.isnan(x['AgeFill']) else x['AgeFill'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fare**: Replace NaN by mean depending on the sex, class and embarkation point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['FareFill'] = df_train['Fare']\n",
    "df_test['FareFill'] = df_test['Fare']\n",
    "\n",
    "fare_median_table = df_train.groupby(['Sex', 'Embarked','Pclass'])['Fare'].median()\n",
    "print fare_median_table\n",
    "\n",
    "def fill_fare_sex_embarked_class(x,base_table):\n",
    "    fare = base_table.loc[x['Sex'], x['Embarked'], x['Pclass']]           \n",
    "    return fare\n",
    "\n",
    "#df_train['FareFill'] = df_train.apply(lambda x: fill_fare_sex_embarked_class(x,fare_median_table) if np.isnan(x['FareFill']) else x['FareFill'], axis=1)\n",
    "df_test['FareFill'] = df_test.apply(lambda x: fill_fare_sex_embarked_class(x,fare_median_table) if np.isnan(x['FareFill']) else x['FareFill'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Prediction_models_1\"></a>\n",
    "# 4. Prediction models (I) - With no further optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace categorical variables (Sex, Embarked, Pclass) by dummy variables\n",
    "dummy_sex = pd.get_dummies(df_train['Sex'], prefix='Sex')\n",
    "dummy_embarked = pd.get_dummies(df_train['Embarked'], prefix='Embarked')\n",
    "dummy_pclass = pd.get_dummies(df_train['Pclass'], prefix='Pclass')\n",
    "\n",
    "# Create a clean data frame for the regression\n",
    "cols_to_keep = ['AgeFill', 'SibSp', 'Parch', 'FareFill']\n",
    "X_train = df_train[cols_to_keep].join(dummy_sex).join(dummy_embarked).join(dummy_pclass)\n",
    "X_train\n",
    "\n",
    "Y_train = df_train['Survived']\n",
    "\n",
    "# Prepare test dataset\n",
    "# Replace categorical variables (Sex, Embarked, Pclass) by dummy variables\n",
    "dummy_sex = pd.get_dummies(df_test['Sex'], prefix='Sex')\n",
    "dummy_embarked = pd.get_dummies(df_test['Embarked'], prefix='Embarked')\n",
    "dummy_pclass = pd.get_dummies(df_test['Pclass'], prefix='Pclass')\n",
    "X_test = df_test[cols_to_keep].join(dummy_sex).join(dummy_embarked).join(dummy_pclass)\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Score a particular model\n",
    "'''\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "def compute_model_score(model, X_train, Y_train, X_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    score = model.score(X_train,Y_train)\n",
    "    return score, Y_pred\n",
    "'''\n",
    "Score a particular model using k-fold cross validation\n",
    "'''\n",
    "def compute_model_score_cv(model, X_train, Y_train, X_test):\n",
    "    fit = model.fit(X_train,Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    x_val = cross_val_score(fit, X_train, Y_train, cv =5, scoring='accuracy')\n",
    "    return np.mean(x_val), Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a table with scores for different models\n",
    "model_list = [{'function': LogisticRegression(), 'name': 'LR'},\n",
    "              {'function': SVC(), 'name': 'SVC'},\n",
    "              {'function': KNeighborsClassifier(n_neighbors = 3), 'name': 'KN-3'},\n",
    "              {'function': DecisionTreeClassifier(), 'name': 'DT'},\n",
    "              {'function': GaussianNB(), 'name': 'GNB'},\n",
    "              {'function': Perceptron(), 'name': 'Perceptron'},\n",
    "              {'function': SGDClassifier(), 'name': 'SGD'},\n",
    "              {'function': RandomForestClassifier(n_estimators=100), 'name': 'Random Forest'}             \n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_results = []\n",
    "\n",
    "for model in model_list:\n",
    "    score, Y_pred = compute_model_score(model['function'], X_train, Y_train, X_test)\n",
    "    score_cv, Y_pred = compute_model_score_cv(model['function'], X_train, Y_train, X_test)\n",
    "    model_results.append([model['name'], score, score_cv, Y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results obtained sorted by score\n",
    "df_model_results = pd.DataFrame (model_results, columns=('Model', 'Score', 'Score-CV', 'Prediction'))  \n",
    "df_model_results.sort_values(by='Score-CV', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze results\n",
    "* TODO: See which variables are more important. This will help us to optimise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write result in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose model and save its prediction\n",
    "#print df_model_results.loc[7]\n",
    "#Y_pred = df_model_results.loc[7]['Prediction']\n",
    "\n",
    "# Take model with best score\n",
    "Y_pred = df_model_results.sort_values(by='Score-CV', ascending=False).iloc[0]['Prediction']\n",
    "print Y_pred\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_test[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred   \n",
    "})  \n",
    " \n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Feature_engineering_2\"></a>\n",
    "# 5. Feature Engineering (II)\n",
    "* Apply domain knowledge to see if we can improve the initial results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FE2_name\"></a>\n",
    "## 5.1. Playing with 'Name'\n",
    "* The variable 'name' contains not only the firstname and surname of the passenger, but also the title. We may extract something useful if we process this feature. Title may be related to social status, which might have an effect on the survival opportunities in the Titanic.\n",
    "* All names in the dataset have the format 'Surname, Title. Name (aka name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the feature to extract all titles\n",
    "def get_title(name):\n",
    "    if '.' in name:\n",
    "        return name.split(',')[1].split('.')[0].strip()\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "#list_titles = sorted(set([x for x in train.Name.map(lambda x: get_title(x))]))\n",
    "list_title = df_train['Name'].apply(lambda x: get_title(x))\n",
    "print list_title.value_counts()\n",
    "\n",
    "#list_title = df_test['Name'].apply(lambda x: get_title(x))\n",
    "#print list_title.value_counts()\n",
    "\n",
    "#df_train[df_train['Name'].str.contains('Master')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having a look on the title, we can notice that there are a few titles that can be merged:\n",
    "* There are not enough occurrences of certain titles. It would be better to create a category for those that seem to belong to cabin crew members\n",
    "* 'Mme' is 'Madame', the French equivalent to Ms. We will transform this title to Miss\n",
    "* 'Mlle' is 'Mademoiselle', the French equivalent to Miss.\n",
    "* 'Col'->Colonel. 'Capt'->Captain. 'Major'\n",
    "* 'Lady' is a noble title, or the wife of a Lord, Baron or Sir.\n",
    "* 'Jonkheer' is Dutch honorific of nobility.\n",
    "* 'Master' is used for male young and unmarried children.\n",
    "* 'Don' is a Spanish noble title. We will merge all noble titles to one value: 'noble'.\n",
    "* 'Rev' is Reverend. Merge it with another title? Think about Dr as well. They could belong to the cabin crew\n",
    "* We will assume that 'Dr' only refers to medical doctors, who could be part of the cabin crew.\n",
    "\n",
    "There might be more honorific titles that are not present in the train data, but in the test data or the score data. It is not possible to take into account all possible titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new feature with the title of each person\n",
    "\n",
    "# Map of titles\n",
    "Title_Dictionary = {\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Mme\":        \"Miss\",\n",
    "    \"Ms\":         \"Miss\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Dr\":         \"Crew\",\n",
    "    \"Rev\":        \"Crew\",\n",
    "    \"Capt\":       \"Crew\",\n",
    "    \"Col\":        \"Crew\",\n",
    "    \"Major\":      \"Crew\",\n",
    "    \"Jonkheer\":   \"Noble\",\n",
    "    \"Don\":        \"Noble\",\n",
    "    \"Dona\":       \"Noble\",\n",
    "    \"Sir\" :       \"Noble\",\n",
    "    \"Lady\" :      \"Noble\",\n",
    "    \"the Countess\":\"Noble\"\n",
    "}\n",
    "\n",
    "df_train['Title'] = df_train['Name'].apply(lambda x: get_title(x))\n",
    "df_train['Title'] = df_train['Title'].map(Title_Dictionary)\n",
    "\n",
    "df_test['Title'] = df_test['Name'].apply(lambda x: get_title(x))\n",
    "df_test['Title'] = df_test['Title'].map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"FE2_age\"></a>\n",
    "## 5.2. Playing with: 'Age'\n",
    "* TODO: Play with the fact that 'Woman and Child first!'\n",
    "* TODO: Possibly create another variables for child (<16) \n",
    "* Estimate the age using the missing titles as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median of age per Sex, Class and Title\n",
    "df_train['AgeFill'] = df_train['Age']\n",
    "df_test['AgeFill'] = df_test['Age']\n",
    "\n",
    "age_median_table = df_train.groupby(['Sex','Pclass','Title'])['Age'].median()\n",
    "print age_median_table\n",
    "\n",
    "def fill_age_sex_class_title(x,base_table):\n",
    "    age = base_table.loc[x['Sex'], x['Pclass'], x['Title']]                 \n",
    "    return age\n",
    "\n",
    "df_train['AgeFill'] = df_train.apply(lambda x: fill_age_sex_class_title(x,age_median_table) if np.isnan(x['AgeFill']) else x['AgeFill'], axis=1)\n",
    "df_test['AgeFill'] = df_test.apply(lambda x: fill_age_sex_class_title(x,age_median_table) if np.isnan(x['AgeFill']) else x['AgeFill'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solve NaN in Age before plotting this\n",
    "figure = plt.figure(figsize=(15,8))\n",
    "plt.hist([df_train[df_train['Survived']==1]['Age'],df_train[df_train['Survived']==0]['Age']], \n",
    "         stacked=True, color = ['g','r'],\n",
    "         bins = 20,label = ['Survived','Dead'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def person(passenger):\n",
    "    age, sex = passenger\n",
    "    if age < 16:\n",
    "        return \"child\"\n",
    "    else:\n",
    "        return dict(male=\"man\", female=\"woman\")[sex]\n",
    "\n",
    "# Create 5 intervals for age\n",
    "#pd.cut(df_train['Age'], 5)\n",
    "\n",
    "# Create a new colum    \n",
    "df_train['Person'] = df_train[['Age','Sex']].apply(person, axis=1)\n",
    "    \n",
    "# Survived by Adults and kids (and sex)\n",
    "#fig_survived_by_age = sns.pointplot('Age', 'Survived', data=df_train)\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_person = sns.countplot('Person', data=df_train, ax=axs[0])\n",
    "fig_survived_by_person = sns.pointplot('Person', 'Survived', data=df_train, ax=axs[1])\n",
    "\n",
    "fig_person.set_title('Distribution by Adults or Kids')\n",
    "fig_survived_by_person.set_title('% survival of Man, Woman and Child')\n",
    "fig_survived_by_person.set(ylim=(0, 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FE2_embarked\"></a>\n",
    "## 5.3. Playing with: 'Embarked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FE2_fare\"></a>\n",
    "## 5.4. Playing with: 'Fare'\n",
    "* **TODO**: It seems that there are errors in the Fare. Change these values for the median of their class\n",
    "* As the distribution of the bin is too skewed, we will create intervals (bins).\n",
    "    * It did not seems that this transformation affected that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking fare errors or free tickets\n",
    "# df_train[['Pclass','Age','Fare']][df_train['Fare']<5]\n",
    "\n",
    "# Create 5 bins to represent the Fare. Create bins using TRAIN dataset\n",
    "df_train['FareBin'], fare_bins = pd.qcut(df_train['FareFill'], 5, retbins=True)\n",
    "df_test['FareBin'] = pd.cut(df_test['FareFill'], bins=fare_bins)\n",
    "print fare_bins\n",
    "\n",
    "# Since qcut() creates a new variable that identifies a range, we need to factorize (sorted) or create dummies\n",
    "df_train['FareBinID'] = pd.factorize(df_train['FareBin'], sort=True)[0]\n",
    "df_test['FareBinID'] = pd.factorize(df_test['FareBin'], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FE2_ticket\"></a>\n",
    "## 5.5. Playing with: 'Ticket'\n",
    "* Ticket seems a difficult variable to process, but there is no nulls in both train and test dataset, and we should be able to extract something meaningful from it\n",
    "* Tickets are either a number, or a alphanumeric prefix + number. This prefix could contain extra info, such as location at the Titanic (deck)\n",
    "* There seems to be a repetition on the ticket number. This may mean people 'travelling together', which could be useful together with FamilyID to cover those cases of extra people travelling with the Family (nannies, servants, etc.) that could have a stronger chance of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ticket nulls in Train=%d; and Test=%d' % (df_train['Ticket'].isnull().sum() , df_test['Ticket'].isnull().sum()))\n",
    "\n",
    "#df_train['Ticket'].describe(include='all')\n",
    "#print df_train['Ticket'].value_counts().head(3)\n",
    "\n",
    "# How many different prefix do we have?\n",
    "def getTicketPrefix(ticket):   \n",
    "    prefix = ticket.split()[0].replace('.','').replace('/','')\n",
    "    if prefix.isdigit():\n",
    "        return 'U'\n",
    "    else:\n",
    "        return prefix\n",
    "    \n",
    "def getTicketNumber(ticket):\n",
    "    ticket_number_pattern = re.compile(\"([0-9]+$)\")\n",
    "    match = ticket_number_pattern.search(ticket)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return 0 # Unknown\n",
    "    \n",
    "# Create multiple features with ticket. We can later discard as many as we want\n",
    "df_train['TicketPrefix'] = df_train['Ticket'].apply(lambda x: getTicketPrefix(x.upper()))\n",
    "df_train['TicketNumber'] = df_train['Ticket'].apply(lambda x: getTicketNumber(x.upper()))\n",
    "df_train['TicketFirstDigit'] = df_train['TicketNumber'].apply(lambda x: str(x)[0]).astype(np.int)\n",
    "df_train['TicketNumDigits'] = df_train['TicketNumber'].apply(lambda x: len(str(x))).astype(np.int)\n",
    "\n",
    "#display(df_train)\n",
    "#display(df_train['TicketPrefix'].value_counts())\n",
    "\n",
    "df_test['TicketPrefix'] = df_test['Ticket'].apply(lambda x: getTicketPrefix(x.upper()))\n",
    "df_test['TicketNumber'] = df_test['Ticket'].apply(lambda x: getTicketNumber(x.upper()))\n",
    "df_test['TicketFirstDigit'] = df_test['TicketNumber'].apply(lambda x: str(x)[0]).astype(np.int)\n",
    "df_test['TicketNumDigits'] = df_test['TicketNumber'].apply(lambda x: len(str(x))).astype(np.int)\n",
    "\n",
    "# Process ticket creating same categories for train and test. Otherwise, we will be getting different columns\n",
    "train_categories = df_train['TicketPrefix'].astype('category').cat.categories.tolist()\n",
    "test_categories = df_test['TicketPrefix'].astype('category').cat.categories.tolist()\n",
    "ticket_categories = list(set().union(train_categories,test_categories))\n",
    "\n",
    "print ticket_categories\n",
    "# Set TicketPrefix feature as categorical, using the previous list\n",
    "df_train['TicketPrefix'] = df_train['TicketPrefix'].astype('category', categories=ticket_categories)\n",
    "df_test['TicketPrefix'] = df_test['TicketPrefix'].astype('category', categories=ticket_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"FE2_sibsp\"></a>\n",
    "## 5.6.  Playing with:  'SibSp' and 'Parch'\n",
    "* SibSp (Number of Siblings/Spouses Aboard) and Parch (Number of Parents/Children Aboard) could be merged into one feature: 'FamilySize'\n",
    "* Create variable 'Alone' (or without family), as derivate of SibSp and Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create 'FamilySize' feature\n",
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 \n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 \n",
    "\n",
    "# Create boolean 'Alone' feature\n",
    "df_train['Alone'] = df_train.apply(lambda x: 1 if (x['FamilySize']==1) \n",
    "                                   else 0, axis=1)\n",
    "df_test['Alone'] = df_test.apply(lambda x: 1 if (x['FamilySize']==1) \n",
    "                                   else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Prediction_models_2\"></a>\n",
    "# 6. Prediction models (II) - After more feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TODO ** Make graph to see the importance of each variable for a model\n",
    "* We will scale the variables. Although Random Forest and decision trees in general are not affected by unnormalised variables, other mother may be affected. \n",
    "    * This made a large improvement on the accuracy, for certain models, such as SVM\n",
    "* Ticket dummies do not seem to improve the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a clean data frame for the regression\n",
    "\n",
    "# Columns to keep\n",
    "cols_to_keep = ['AgeFill', 'SibSp', 'Parch', 'FareFill', 'FamilySize', 'Alone']\n",
    "#cols_to_keep = ['AgeFill', 'SibSp', 'Parch', 'FareBinID', 'FamilySize', 'Alone', 'TicketFirstDigit', 'TicketNumDigits']\n",
    "##cols_to_drop = ['TicketPrefix', 'TicketNumber', 'TicketFirstDigit', 'TicketNumDigits']\n",
    "\n",
    "# Replace categorical variables by dummy variables\n",
    "cols_dummy = ['Sex', 'Embarked', 'Pclass', 'Title']\n",
    "#cols_dummy = ['Sex', 'Embarked', 'Pclass', 'Title', 'TicketPrefix'] # Worse accuracy\n",
    "\n",
    "# Training set\n",
    "X_train = df_train[cols_to_keep].join(\n",
    "    pd.get_dummies(df_train[cols_dummy], prefix=cols_dummy, columns=cols_dummy))\n",
    "\n",
    "# Target\n",
    "Y_train = df_train['Survived']\n",
    "\n",
    "# Test set\n",
    "X_test = df_test[cols_to_keep].join(\n",
    "    pd.get_dummies(df_test[cols_dummy], prefix=cols_dummy, columns=cols_dummy))\n",
    "\n",
    "# Scale features\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_results = []\n",
    "X_train_ = X_train_std\n",
    "X_test_ = X_test_std\n",
    "\n",
    "for model in model_list:\n",
    "    score, Y_pred = compute_model_score(model['function'], X_train_, Y_train, X_test_)\n",
    "    score_cv, Y_pred = compute_model_score_cv(model['function'], X_train_, Y_train, X_test_)\n",
    "    model_results.append([model['name'], score, score_cv, Y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results obtained sorted by score\n",
    "df_model_results = pd.DataFrame (model_results, columns=('Model', 'Score', 'Score-CV', 'Prediction'))  \n",
    "df_model_results.sort_values(by='Score-CV', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
    "fit = model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "features['feature'] = X_train.columns\n",
    "features['importance'] = fit.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "#features.set_index('feature', inplace=True)\n",
    "features = features.reset_index(drop=True)\n",
    "sns.barplot(data=features, y='feature', x='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model and save its prediction\n",
    "#print df_model_results.loc[7]\n",
    "#Y_pred = df_model_results.loc[7]['Prediction']\n",
    "\n",
    "# Take model with best score\n",
    "Y_pred = df_model_results.sort_values(by='Score-CV', ascending=False).iloc[0]['Prediction']\n",
    "print Y_pred\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_test[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred   \n",
    "})  \n",
    " \n",
    "submission.to_csv('submission_LR.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
