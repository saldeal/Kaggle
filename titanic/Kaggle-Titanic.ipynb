{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kaggle - Titanic - Survival prediction\n",
    "## [1. Reading train and test data](#Reading_data)\n",
    "## [2. Exploration of the data](#Data_exploration)\n",
    "## [3. Feature engineering (I) - Filling the NaNs](#Feature_engineering_1)\n",
    "## [4. Prediction models (I)](#Prediction_models_1)\n",
    "## [5. Feature engineering (II)](#Feature_engineering_2)\n",
    "> ### [5.1 Playing with: 'Name'](#FE2_name)\n",
    "> ### [5.2 Playing with: 'Age'](#FE2_Age)\n",
    "> ### [5.3 Playing with: 'Embarked'](#FE2_embarked)\n",
    "> ### [5.4 Playing with: 'Fare'](#FE2_fare)\n",
    "> ### [5.5 Playing with: 'Ticket'](#FE2_ticket)\n",
    "> ### [5.6 Playing with: 'Sibsp' and 'Parch'](#FE2_sibsp)\n",
    "\n",
    "## [6. Prediction models (II)](#Prediction_models_2)\n",
    "\n",
    "## [7. Feature selection](#Feature_selection)\n",
    "\n",
    "## [8. Model tuning](#Model_tuning)\n",
    "\n",
    "## [9. Model evaluation](#Model_evaluation)\n",
    "\n",
    "## [Save predictions to CSV](#Save_predictions)\n",
    "\n",
    "<a id=\"Reading_data\"></a> \n",
    "# 1. Reading train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5891a84120ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#from sklearn.cross_validation import cross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set() # Plot style\n",
    "\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "IPython.core.pylabtools.figsize(12, 4)\n",
    "\n",
    "# Import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open CSV file for train data and test data\n",
    "df = []\n",
    "df.append(pd.read_csv('data/train.csv'))\n",
    "df.append(pd.read_csv('data/test.csv'))\n",
    "\n",
    "# Create two different pointers to the train and the test data\n",
    "df_train = df[0]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df[1]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combined = df[0].append(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print df_train.shape\n",
    "#print combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create submission\n",
    "def create_submission_from_list(Y_pred, filename):\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_test[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred   \n",
    "    })  \n",
    " \n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Data_exploration\"></a>\n",
    "# 2. Exploration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Analysis of null in training dataset'\n",
    "print '-----------------------------------'\n",
    "print 'Passenger_id nulls: ' + str(df_train['PassengerId'].isnull().sum())\n",
    "print 'Pclass nulls: ' + str(df_train['Pclass'].isnull().sum())\n",
    "print 'Age nulls: ' + str(df_train['Age'].isnull().sum())\n",
    "print 'SibSp nulls: ' + str(df_train['SibSp'].isnull().sum())\n",
    "print 'Parch nulls: ' + str(df_train['Parch'].isnull().sum())\n",
    "print 'Ticket nulls: ' + str(df_train['Ticket'].isnull().sum())\n",
    "print 'Fare nulls: ' + str(df_train['Fare'].isnull().sum())\n",
    "print 'Cabin nulls: ' + str(df_train['Cabin'].isnull().sum())\n",
    "print 'Embarked nulls: ' + str(df_train['Embarked'].isnull().sum())\n",
    "print '-----------------------------------'\n",
    "nan_rows = df_train[df_train['Age'].isnull()]\n",
    "nan_rows.loc[:,:].head()\n",
    "\n",
    "# Most frequent value per column\n",
    "print 'Mean/Median/Mode in training dataset per column'\n",
    "print '-----------------------------------'\n",
    "print 'Embarked:'\n",
    "print df_train['Embarked'].value_counts()\n",
    "\n",
    "print \"Fare: Mean = %f , Median = %f , Mode = %f\" % (df_train['Fare'].mean(),df_train['Fare'].median(),df_train['Fare'].mode())\n",
    "#print \"Fare: Mean = %f , Median = %f , Mode = %f\" % (df_train['Ticket'].mean(),df_train['Ticket'].median(),df_train['Ticket'].mode())\n",
    "print 'Ticket:'\n",
    "print df_train['Ticket'].value_counts().head()\n",
    "print \"Age: Mean = %f , Median = %f , Mode = %f\" % (df_train['Age'].mean(),df_train['Age'].median(),df_train['Age'].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "* Min(Fare) is 0. This could mean that there are babies (for example) free of charge, or actually errors.\n",
    "* We need to check the distribution of Fare prices, and decide whether making buckets or not.\n",
    "* There are 2 nulls in 'Embarked'. Replace NaN by 'S', by far the most repeated value.\n",
    "* Cabin nulls may mean people without a cabin, hence, there were less cabins than people.\n",
    "* Ticket is alphanumeric\n",
    "* We have five categorical variables: Sex, Embarked, Class, and Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Ratio of survival in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_passengers_train = df_train.shape[0]\n",
    "print 'Number of passengers: ' + str(num_passengers_train)\n",
    "\n",
    "#num_passengers_survived_train = df_train.groupby('Survived').size()[1]\n",
    "num_passengers_survived_train = df_train[df_train['Survived']==1].shape[0]\n",
    "print 'Number of survivors: ' + str(num_passengers_survived_train)\n",
    "\n",
    "ratio_survival = (num_passengers_survived_train/num_passengers_train)\n",
    "print 'Survival ratio in training data = ' + str(round(ratio_survival*100,2)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Men vs women survival ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Break by men and women\n",
    "women_train = df_train[df_train['Sex']=='female']\n",
    "men_train = df_train[df_train['Sex']=='male']\n",
    "\n",
    "num_women_train = women_train.shape[0]\n",
    "num_men_train = men_train.shape[0]\n",
    "print 'Women on board: ' + str(num_women_train)\n",
    "print 'Men on board: ' + str(num_men_train)\n",
    "\n",
    "num_women_survived_train = women_train[women_train['Survived']==1].shape[0]\n",
    "num_men_survived_train = men_train[men_train['Survived']==1].shape[0]\n",
    "\n",
    "\n",
    "ratio_survival_women = (num_women_survived_train/num_women_train)\n",
    "ratio_survival_men = (num_men_survived_train/num_men_train)\n",
    "\n",
    "print 'Survival ratio for women in training data = ' + str(round(ratio_survival_women*100,2)) + \"%\"\n",
    "print 'Survival ratio for men in training data = ' + str(round(ratio_survival_men*100,2)) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data Visualisation\n",
    "* Constrast different subsets of variables to hint correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Survived vs Pclass and Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First row\n",
    "# Survivors and classes\n",
    "fig, axs = plt.subplots(ncols=3)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_survived = sns.countplot('Survived', data=df_train, ax=axs[0])\n",
    "fig_pclass = sns.countplot('Pclass', data=df_train, ax=axs[1])\n",
    "fig_survived_per_class = sns.pointplot('Pclass', 'Survived', data=df_train, ax=axs[2])\n",
    "\n",
    "fig_survived_per_class.set(ylim=(0,1))\n",
    "fig_survived.set_title('Number of survivors')\n",
    "fig_pclass.set_title('People per class') \n",
    "fig_survived_per_class.set_title('% survival per class')\n",
    "\n",
    "# Second row\n",
    "# Proportion of survivors per class and sex\n",
    "fig, axs = plt.subplots(ncols=3)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_sex = sns.countplot('Sex', data=df_train, ax=axs[0])\n",
    "fig_survived_by_sex = sns.pointplot('Sex', 'Survived', data=df_train, ax=axs[1])\n",
    "fig_survived_by_sex_class = sns.pointplot('Pclass', 'Survived', data=df_train, hue='Sex', ax=axs[2])\n",
    "\n",
    "fig_sex.set_title('People per sex')\n",
    "fig_survived_by_sex.set_title('% survival per sex')\n",
    "fig_survived_by_sex.set(ylim=(0, 1.1))\n",
    "fig_survived_by_sex_class.set_title('% survival per sex & class')\n",
    "fig_survived_by_sex_class.set(ylim=(0, 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* The lower the class (3 is worst class than 1), the less the ratio of survival\n",
    "* Females have an incredible ratio of survival compare to male\n",
    "* \"Women and children first\" seems to be true. Check later the age to verify\n",
    "* Both Sex and Class seems very important for the survival ratio\n",
    "\n",
    "#### Actions\n",
    "* Sex and Class need to be included in the model\n",
    "* Check the real impact of these variables in the models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Survived vs embarkation point, class and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third row\n",
    "# Proportion of survivors per embarked. Class per embark point\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_embarked = sns.countplot('Embarked', data=df_train, ax=axs[0])\n",
    "fig_survived_by_embarked = sns.pointplot('Embarked', 'Survived', data=df_train, ax=axs[1])\n",
    "\n",
    "fig_embarked.set_title('People per port')\n",
    "fig_survived_by_embarked.set_title('% survival per port of embarkation')\n",
    "\n",
    "# Fourth row\n",
    "grid = sns.FacetGrid(df_train, col='Embarked', size=3.5, aspect=1)\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* The embarkation port seems to influence, specially in port C \n",
    "* Note that 'Male' survival is almost 100% for those who embarked from C, while female is signicantly lower!\n",
    "* Very low rate of survivals from port Q\n",
    "* Question: embarkation point could determine the cabin, and the location of the cabin in the Titanic could have been essential, depending on the point of impact with the iceberg\n",
    "\n",
    "#### Actions\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Survived vs Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Distribution of survived and dead by age\n",
    "g = sns.FacetGrid(df_train, col='Survived', size=4, aspect=1)\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#fig = sns.FacetGrid(df_train, hue='Pclass', size=3, aspect=3)\n",
    "#fig.map(sns.kdeplot, 'Fare', shade=True, legend=True)\n",
    "#fig.set(xlim=(0, 80));\n",
    "#fig.set(ylim=(0, 0.1));\n",
    "#fig.add_legend()\n",
    "\n",
    "# Distribution of age by class\n",
    "fig = sns.FacetGrid(df_train, hue='Pclass', size=3, aspect=3)\n",
    "fig.map(sns.kdeplot, 'Age', shade=True)\n",
    "fig.set(xlim=(0, 80));\n",
    "fig.set(ylim=(0, 0.1));\n",
    "fig.add_legend()\n",
    "\n",
    "# Median of Age per class\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_median_age_class = sns.barplot(data=df_train, x='Pclass', y='Age', estimator=np.median, ax=axs[0])\n",
    "fig_mean_age_class = sns.barplot(data=df_train, x='Pclass', y='Age', estimator=np.mean, ax=axs[1])\n",
    "\n",
    "fig_median_age_class.set_title('Median of Age per class')\n",
    "fig_mean_age_class.set_title('Mean of Age per class')\n",
    "\n",
    "print 'Median of Age for all classes: ' + str(df_train['Age'].median()) + ' years'\n",
    "print 'Median of Age for class 1: ' + str(df_train[df_train['Pclass']==1]['Age'].median()) + ' years'\n",
    "print 'Median of Age for class 2: ' + str(df_train[df_train['Pclass']==2]['Age'].median()) + ' years'\n",
    "print 'Median of Age for class 3: ' + str(df_train[df_train['Pclass']==3]['Age'].median()) + ' years'\n",
    "\n",
    "df_train[(df_train['Pclass']==3) & (df_train['Embarked']=='S')]\n",
    "g = sns.FacetGrid(df_train, col='Pclass', size=4, aspect=1)\n",
    "g.map(plt.hist, 'Age', bins = 20)\n",
    "\n",
    "#g = sns.FacetGrid(df_train, col='Embarked', size=4, aspect=1)\n",
    "#g.map(plt.hist, 'Age', bins = 20)\n",
    "\n",
    "# Age by class and embarkation point\n",
    "g = sns.FacetGrid(df_train, row='Embarked', col='Pclass', size=2, aspect=2, margin_titles=True)\n",
    "g.map(plt.hist, 'Age', bins = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many were not adults?\n",
    "print 'How many kids in the titanic (train dataset) (<16): ' + str(len(df_train[df_train['Age']<16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* There are a few children (<16). This could affect the survival ratio\n",
    "* Create buckets/bins for Age could be benefitial\n",
    "* Median/mean of age differs depending on the class. It makes senses, the older people would be wealthier\n",
    "#### Actions\n",
    "* Create a new variable 'Person' to distinguish between Woman, Man, and Child\n",
    "* Try creating a new variable 'Age_range' with 5-6 intervals\n",
    "* Fill NaN values in Age by taking the median per class (Consider embarkation point as well?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Cabin vs Survived\n",
    "* Understanding of Cabin codes, and how this could have affected the survival ratio (Titanic's sink was at night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Survived vs Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.describe()\n",
    "print 'Fare nulls: ' + str(df_train['Fare'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Distribution of Fare\n",
    "sns.distplot(df_train['Fare'].dropna(), kde=True, rug=False)\n",
    "plt.suptitle('Distribution of Fares')\n",
    "#sns.distplot(df_train['Pclass'=='1'], kde=True, rug=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Distribution of Fares by class')\n",
    "sns.distplot(df_train[df_train['Pclass']==3]['Fare'], kde=True, rug=False, ax=ax, label=\"Class 3\")\n",
    "sns.distplot(df_train[df_train['Pclass']==2]['Fare'], kde=True, rug=False, ax=ax, label=\"Class 2\")\n",
    "sns.distplot(df_train[df_train['Pclass']==1]['Fare'], kde=True, rug=False, ax=ax, label=\"Class 1\")\n",
    "plt.legend()\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,0.10])\n",
    "g = sns.FacetGrid(df_train, col='Pclass', size=4, aspect=1)\n",
    "g.map(plt.hist, 'Fare', bins = 20)\n",
    "\n",
    "\n",
    "#g = sns.FacetGrid(df_train, col='Survived', size=4, aspect=1)\n",
    "#g.map(plt.hist, 'Fare', bins=20)\n",
    "\n",
    "figure = plt.figure(figsize=(15,8))\n",
    "plt.hist([df_train[df_train['Survived']==1]['Fare'],df_train[df_train['Survived']==0]['Fare']], \n",
    "         stacked=True, color = ['g','r'],\n",
    "         bins = 20,label = ['Survived','Dead'])\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "* Most of the people pay less than 40 for the ticket\n",
    "* The more someone paid, the better survival ratio. Those who paid more than 100, almost guaranteed their survival\n",
    "* Fare is very skewed.\n",
    "#### Actions\n",
    "* Create intervals for 'Fare'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Feature_engineering_1\"></a> \n",
    "# 3. Feature engineering (I) - Only basic stuff to be able to run our first model\n",
    "* Check if there are NaN values in certain columns, such as Embarked, and replace them by other values\n",
    "* Data imputation is done in both train and test datasets, but only taking information from the train dataset. This way we avoid to include information from the test dataset into the train one. We may get higher accuracy by also exploring the test dataset, but this is not a good practice\n",
    "* We will create new features for data imputation, so we can always go back and apply different transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embarked**: Replace NaN in embarked by 'S', by far the most repeated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked nulls in train: 0\n",
      "Embarked nulls in test: 0\n"
     ]
    }
   ],
   "source": [
    "df_train['Embarked'] = df_train['Embarked'].fillna('S')\n",
    "print 'Embarked nulls in train: ' + str(df_train['Embarked'].isnull().sum())\n",
    "\n",
    "df_test['Embarked'] = df_test['Embarked'].fillna('S')\n",
    "print 'Embarked nulls in test: ' + str(df_test['Embarked'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**: Replace NaN by median depending on the class and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex     Pclass\n",
      "female  1         35.0\n",
      "        2         28.0\n",
      "        3         21.5\n",
      "male    1         40.0\n",
      "        2         30.0\n",
      "        3         25.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median per class\n",
    "df_train['AgeFill'] = df_train['Age']\n",
    "df_test['AgeFill'] = df_test['Age']\n",
    "\n",
    "age_median_table = df_train.groupby(['Sex','Pclass'])['Age'].median()\n",
    "print age_median_table\n",
    "\n",
    "def fill_age_sex_class(x,base_table):\n",
    "    age = base_table.loc[x['Sex'], x['Pclass']]                 \n",
    "    return age\n",
    "\n",
    "df_train['AgeFill'] = df_train.apply(lambda x: fill_age_sex_class(x,age_median_table) if np.isnan(x['AgeFill']) else x['AgeFill'], axis=1)\n",
    "df_test['AgeFill'] = df_test.apply(lambda x: fill_age_sex_class(x,age_median_table) if np.isnan(x['AgeFill']) else x['AgeFill'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fare**: Replace NaN by mean depending on the sex, class and embarkation point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex     Embarked  Pclass\n",
      "female  C         1         83.1583\n",
      "                  2         24.0000\n",
      "                  3         14.4583\n",
      "        Q         1         90.0000\n",
      "                  2         12.3500\n",
      "                  3          7.7500\n",
      "        S         1         79.8250\n",
      "                  2         23.0000\n",
      "                  3         14.4500\n",
      "male    C         1         61.6792\n",
      "                  2         25.8604\n",
      "                  3          7.2292\n",
      "        Q         1         90.0000\n",
      "                  2         12.3500\n",
      "                  3          7.7500\n",
      "        S         1         35.0000\n",
      "                  2         13.0000\n",
      "                  3          8.0500\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train['FareFill'] = df_train['Fare']\n",
    "df_test['FareFill'] = df_test['Fare']\n",
    "\n",
    "fare_median_table = df_train.groupby(['Sex', 'Embarked','Pclass'])['Fare'].median()\n",
    "print fare_median_table\n",
    "\n",
    "def fill_fare_sex_embarked_class(x,base_table):\n",
    "    fare = base_table.loc[x['Sex'], x['Embarked'], x['Pclass']]           \n",
    "    return fare\n",
    "\n",
    "#df_train['FareFill'] = df_train.apply(lambda x: fill_fare_sex_embarked_class(x,fare_median_table) if np.isnan(x['FareFill']) else x['FareFill'], axis=1)\n",
    "df_test['FareFill'] = df_test.apply(lambda x: fill_fare_sex_embarked_class(x,fare_median_table) if np.isnan(x['FareFill']) else x['FareFill'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Prediction_models_1\"></a>\n",
    "# 4. Prediction models (I) - With no further optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace categorical variables (Sex, Embarked, Pclass) by dummy variables\n",
    "dummy_sex = pd.get_dummies(df_train['Sex'], prefix='Sex')\n",
    "dummy_embarked = pd.get_dummies(df_train['Embarked'], prefix='Embarked')\n",
    "dummy_pclass = pd.get_dummies(df_train['Pclass'], prefix='Pclass')\n",
    "\n",
    "# Create a clean data frame for the regression\n",
    "cols_to_keep = ['AgeFill', 'SibSp', 'Parch', 'FareFill']\n",
    "X_train = df_train[cols_to_keep].join(dummy_sex).join(dummy_embarked).join(dummy_pclass)\n",
    "X_train\n",
    "\n",
    "Y_train = df_train['Survived']\n",
    "\n",
    "# Prepare test dataset\n",
    "# Replace categorical variables (Sex, Embarked, Pclass) by dummy variables\n",
    "dummy_sex = pd.get_dummies(df_test['Sex'], prefix='Sex')\n",
    "dummy_embarked = pd.get_dummies(df_test['Embarked'], prefix='Embarked')\n",
    "dummy_pclass = pd.get_dummies(df_test['Pclass'], prefix='Pclass')\n",
    "X_test = df_test[cols_to_keep].join(dummy_sex).join(dummy_embarked).join(dummy_pclass)\n",
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Score a particular model\n",
    "'''\n",
    "def compute_model_score(model, X_train, Y_train, X_test):\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    score = model.score(X_train,Y_train)\n",
    "    return score, Y_pred\n",
    "'''\n",
    "Score a particular model using k-fold cross validation\n",
    "'''\n",
    "def compute_model_score_cv(model, X_train, Y_train, X_test):\n",
    "    fit = model.fit(X_train,Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    x_val = cross_val_score(fit, X_train, Y_train, cv =5, scoring='accuracy')\n",
    "    return np.mean(x_val), Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8412b84d012e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0;34m{\u001b[0m\u001b[0;34m'function'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'SGD'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0;34m{\u001b[0m\u001b[0;34m'function'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Random Forest'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               \u001b[0;34m{\u001b[0m\u001b[0;34m'function'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'XGBoost'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m              ]\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Build a table with scores for different models\n",
    "model_list = [{'function': LogisticRegression(), 'name': 'LR'},\n",
    "              {'function': SVC(), 'name': 'SVC'},\n",
    "              {'function': KNeighborsClassifier(n_neighbors = 3), 'name': 'KN-3'},\n",
    "              {'function': DecisionTreeClassifier(), 'name': 'DT'},\n",
    "              {'function': GaussianNB(), 'name': 'GNB'},\n",
    "              {'function': Perceptron(), 'name': 'Perceptron'},\n",
    "              {'function': SGDClassifier(), 'name': 'SGD'},\n",
    "              {'function': RandomForestClassifier(n_estimators=100), 'name': 'Random Forest'},\n",
    "              {'function': XGBClassifier(), 'name': 'XGBoost'}\n",
    "             ]\n",
    "\n",
    "# Iterate over different models to get a score\n",
    "def get_scores(model_list, X_train, Y_train, X_test):\n",
    "    model_results = []\n",
    "    for model in model_list:\n",
    "        score, Y_pred = compute_model_score(model['function'], X_train, Y_train, X_test)\n",
    "        score_cv, Y_pred = compute_model_score_cv(model['function'], X_train, Y_train, X_test)\n",
    "        model_results.append([model['name'], score, score_cv, Y_pred])    \n",
    "    return model_results\n",
    "\n",
    "# Show results obtained sorted by score\n",
    "def print_scores(model_results, columns=('Model', 'Score', 'Score-CV', 'Prediction')):\n",
    "    df_model_results = pd.DataFrame (model_results, columns=columns)  \n",
    "    df_sorted = df_model_results.sort_values(by='Score-CV', ascending=False)\n",
    "    display(df_sorted)\n",
    "    \n",
    "    return df_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Score-CV</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.867565</td>\n",
       "      <td>0.821616</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.980920</td>\n",
       "      <td>0.804812</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.800287</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GNB</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.783476</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.980920</td>\n",
       "      <td>0.778919</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.682379</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.891134</td>\n",
       "      <td>0.729625</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KN-3</td>\n",
       "      <td>0.843996</td>\n",
       "      <td>0.723988</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.686050</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model     Score  Score-CV  \\\n",
       "8        XGBoost  0.867565  0.821616   \n",
       "7  Random Forest  0.980920  0.804812   \n",
       "0             LR  0.808081  0.800287   \n",
       "4            GNB  0.785634  0.783476   \n",
       "3             DT  0.980920  0.778919   \n",
       "6            SGD  0.682379  0.735294   \n",
       "1            SVC  0.891134  0.729625   \n",
       "2           KN-3  0.843996  0.723988   \n",
       "5     Perceptron  0.740741  0.686050   \n",
       "\n",
       "                                          Prediction  \n",
       "8  [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "7  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "0  [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "4  [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "3  [0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "6  [1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, ...  \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, ...  \n",
       "2  [0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, ...  \n",
       "5  [0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results = get_scores(model_list, X_train, Y_train, X_test)\n",
    "df_model_results = print_scores(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write result in a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take model with best score\n",
    "Y_pred = df_model_results.sort_values(by='Score-CV', ascending=False).iloc[0]['Prediction']\n",
    "create_submission_from_list(Y_pred,'submission_best.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Feature_engineering_2\"></a>\n",
    "# 5. Feature Engineering (II)\n",
    "* Apply domain knowledge to see if we can improve the initial results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FE2_name\"></a>\n",
    "## 5.1. Playing with 'Name'\n",
    "* The variable 'name' contains not only the firstname and surname of the passenger, but also the title. We may extract something useful if we process this feature. Title may be related to social status, which might have an effect on the survival opportunities in the Titanic.\n",
    "* All names in the dataset have the format 'Surname, Title. Name (aka name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr              517\n",
      "Miss            182\n",
      "Mrs             125\n",
      "Master           40\n",
      "Dr                7\n",
      "Rev               6\n",
      "Mlle              2\n",
      "Col               2\n",
      "Major             2\n",
      "Lady              1\n",
      "Jonkheer          1\n",
      "Don               1\n",
      "Ms                1\n",
      "Mme               1\n",
      "Capt              1\n",
      "the Countess      1\n",
      "Sir               1\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Parse the feature to extract all titles\n",
    "def get_title(name):\n",
    "    if '.' in name:\n",
    "        return name.split(',')[1].split('.')[0].strip()\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "#list_titles = sorted(set([x for x in train.Name.map(lambda x: get_title(x))]))\n",
    "list_title = df_train['Name'].apply(lambda x: get_title(x))\n",
    "print list_title.value_counts()\n",
    "\n",
    "#list_title = df_test['Name'].apply(lambda x: get_title(x))\n",
    "#print list_title.value_counts()\n",
    "\n",
    "#df_train[df_train['Name'].str.contains('Master')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having a look on the title, we can notice that there are a few titles that can be merged:\n",
    "* There are not enough occurrences of certain titles. It would be better to create a category for those that seem to belong to cabin crew members\n",
    "* 'Mme' is 'Madame', the French equivalent to Ms. We will transform this title to Miss\n",
    "* 'Mlle' is 'Mademoiselle', the French equivalent to Miss.\n",
    "* 'Col'->Colonel. 'Capt'->Captain. 'Major'\n",
    "* 'Lady' is a noble title, or the wife of a Lord, Baron or Sir.\n",
    "* 'Jonkheer' is Dutch honorific of nobility.\n",
    "* 'Master' is used for male young and unmarried children.\n",
    "* 'Don' is a Spanish noble title. We will merge all noble titles to one value: 'noble'.\n",
    "* 'Rev' is Reverend. Merge it with another title? Think about Dr as well. They could belong to the cabin crew\n",
    "* We will assume that 'Dr' only refers to medical doctors, who could be part of the cabin crew.\n",
    "\n",
    "There might be more honorific titles that are not present in the train data, but in the test data or the score data. It is not possible to take into account all possible titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new feature with the title of each person\n",
    "\n",
    "# Map of titles\n",
    "Title_Dictionary = {\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Mme\":        \"Miss\",\n",
    "    \"Ms\":         \"Miss\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Dr\":         \"Crew\",\n",
    "    \"Rev\":        \"Crew\",\n",
    "    \"Capt\":       \"Crew\",\n",
    "    \"Col\":        \"Crew\",\n",
    "    \"Major\":      \"Crew\",\n",
    "    \"Jonkheer\":   \"Noble\",\n",
    "    \"Don\":        \"Noble\",\n",
    "    \"Dona\":       \"Noble\",\n",
    "    \"Sir\" :       \"Noble\",\n",
    "    \"Lady\" :      \"Noble\",\n",
    "    \"the Countess\":\"Noble\"\n",
    "}\n",
    "\n",
    "df_train['Title'] = df_train['Name'].apply(lambda x: get_title(x))\n",
    "df_train['Title'] = df_train['Title'].map(Title_Dictionary)\n",
    "\n",
    "df_test['Title'] = df_test['Name'].apply(lambda x: get_title(x))\n",
    "df_test['Title'] = df_test['Title'].map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"FE2_age\"></a>\n",
    "## 5.2. Playing with: 'Age'\n",
    "* Play with the fact that 'Woman and Child first!'\n",
    "    * TODO: Possibly create another variables for child (<16) \n",
    "* Estimate the age using the missing titles as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex     Pclass  Title \n",
      "female  1       Crew      49.0\n",
      "                Miss      29.5\n",
      "                Mrs       41.5\n",
      "                Noble     40.5\n",
      "        2       Miss      24.0\n",
      "                Mrs       32.0\n",
      "        3       Miss      18.0\n",
      "                Mrs       31.0\n",
      "male    1       Crew      51.0\n",
      "                Master     4.0\n",
      "                Mr        40.0\n",
      "                Noble     40.0\n",
      "        2       Crew      46.5\n",
      "                Master     1.0\n",
      "                Mr        31.0\n",
      "        3       Master     4.0\n",
      "                Mr        26.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median of age per Sex, Class and Title\n",
    "df_train['AgeFill'] = df_train['Age']\n",
    "df_test['AgeFill'] = df_test['Age']\n",
    "\n",
    "age_median_table = df_train.groupby(['Sex','Pclass','Title'])['Age'].median()\n",
    "print age_median_table\n",
    "\n",
    "def fill_age_sex_class_title(x,base_table):\n",
    "    age = base_table.loc[x['Sex'], x['Pclass'], x['Title']]                 \n",
    "    return age\n",
    "\n",
    "df_train['AgeFill'] = df_train.apply(lambda x: fill_age_sex_class_title(x,age_median_table) if np.isnan(x['AgeFill']) else x['AgeFill'], axis=1)\n",
    "df_test['AgeFill'] = df_test.apply(lambda x: fill_age_sex_class_title(x,age_median_table) if np.isnan(x['AgeFill']) else x['AgeFill'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solve NaN in Age before plotting this\n",
    "figure = plt.figure(figsize=(15,8))\n",
    "plt.hist([df_train[df_train['Survived']==1]['AgeFill'],df_train[df_train['Survived']==0]['AgeFill']], \n",
    "         stacked=True, color = ['g','r'],\n",
    "         bins = 20,label = ['Survived','Dead'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def person(passenger):\n",
    "    age, sex = passenger\n",
    "    if age < 16:\n",
    "        return \"child\"\n",
    "    else:\n",
    "        return dict(male=\"man\", female=\"woman\")[sex]\n",
    "\n",
    "# Create 5 intervals for age\n",
    "#pd.cut(df_train['Age'], 5)\n",
    "\n",
    "# Create a new colum    \n",
    "df_train['Person'] = df_train[['Age','Sex']].apply(person, axis=1)\n",
    "df_test['Person'] = df_test[['Age','Sex']].apply(person, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Survived by Adults and kids (and sex)\n",
    "#fig_survived_by_age = sns.pointplot('Age', 'Survived', data=df_train)\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.2)\n",
    "fig_person = sns.countplot('Person', data=df_train, ax=axs[0])\n",
    "fig_survived_by_person = sns.pointplot('Person', 'Survived', data=df_train, ax=axs[1])\n",
    "\n",
    "fig_person.set_title('Distribution by Adults or Kids')\n",
    "fig_survived_by_person.set_title('% survival of Man, Woman and Child')\n",
    "fig_survived_by_person.set(ylim=(0, 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FE2_embarked\"></a>\n",
    "## 5.3. Playing with: 'Embarked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FE2_fare\"></a>\n",
    "## 5.4. Playing with: 'Fare'\n",
    "* **TODO**: It seems that there are errors in the Fare. Change these values for the median of their class\n",
    "* As the distribution of the bin is too skewed, we will create intervals (bins).\n",
    "    * It did not seems that this transformation affected that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.        7.8542   10.5      21.6792   39.6875  512.3292]\n"
     ]
    }
   ],
   "source": [
    "# Checking fare errors or free tickets\n",
    "# df_train[['Pclass','Age','Fare']][df_train['Fare']<5]\n",
    "\n",
    "# Create 5 bins to represent the Fare. Create bins using TRAIN dataset\n",
    "df_train['FareBin'], fare_bins = pd.qcut(df_train['FareFill'], 5, retbins=True)\n",
    "df_test['FareBin'] = pd.cut(df_test['FareFill'], bins=fare_bins)\n",
    "print fare_bins\n",
    "\n",
    "# Since qcut() creates a new variable that identifies a range, we need to factorize (sorted) or create dummies\n",
    "df_train['FareBinID'] = pd.factorize(df_train['FareBin'], sort=True)[0]\n",
    "df_test['FareBinID'] = pd.factorize(df_test['FareBin'], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"FE2_ticket\"></a>\n",
    "## 5.5. Playing with: 'Ticket'\n",
    "* Ticket seems a difficult variable to process, but there is no nulls in both train and test dataset, and we should be able to extract something meaningful from it\n",
    "* Tickets are either a number, or a alphanumeric prefix + number. This prefix could contain extra info, such as location at the Titanic (deck)\n",
    "* There seems to be a repetition on the ticket number. This may mean people 'travelling together', which could be useful together with FamilyID to cover those cases of extra people travelling with the Family (nannies, servants, etc.) that could have a stronger chance of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket nulls in Train=0; and Test=0\n",
      "['SCAH', 'WC', 'STONO', 'FCC', 'SOPP', 'FA', 'FC', 'LINE', 'SWPP', 'PP', 'SOP', 'SOTONOQ', 'STONOQ', 'PC', 'PPP', 'A5', 'A4', 'LP', 'SCPARIS', 'A', 'AQ4', 'C', 'AQ3', 'SOTONO2', 'CA', 'SOC', 'AS', 'STONO2', 'U', 'SP', 'SCOW', 'WEP', 'CASOTON', 'SC', 'SCA3', 'SCA4']\n"
     ]
    }
   ],
   "source": [
    "print('Ticket nulls in Train=%d; and Test=%d' % (df_train['Ticket'].isnull().sum() , df_test['Ticket'].isnull().sum()))\n",
    "\n",
    "#df_train['Ticket'].describe(include='all')\n",
    "#print df_train['Ticket'].value_counts().head(3)\n",
    "\n",
    "# How many different prefix do we have?\n",
    "def getTicketPrefix(ticket):   \n",
    "    prefix = ticket.split()[0].replace('.','').replace('/','')\n",
    "    if prefix.isdigit():\n",
    "        return 'U'\n",
    "    else:\n",
    "        return prefix\n",
    "    \n",
    "def getTicketNumber(ticket):\n",
    "    ticket_number_pattern = re.compile(\"([0-9]+$)\")\n",
    "    match = ticket_number_pattern.search(ticket)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return 0 # Unknown\n",
    "    \n",
    "# Create multiple features with ticket. We can later discard as many as we want\n",
    "df_train['TicketPrefix'] = df_train['Ticket'].apply(lambda x: getTicketPrefix(x.upper()))\n",
    "df_train['TicketNumber'] = df_train['Ticket'].apply(lambda x: getTicketNumber(x.upper()))\n",
    "df_train['TicketFirstDigit'] = df_train['TicketNumber'].apply(lambda x: str(x)[0]).astype(np.int)\n",
    "df_train['TicketNumDigits'] = df_train['TicketNumber'].apply(lambda x: len(str(x))).astype(np.int)\n",
    "\n",
    "#display(df_train)\n",
    "#display(df_train['TicketPrefix'].value_counts())\n",
    "\n",
    "df_test['TicketPrefix'] = df_test['Ticket'].apply(lambda x: getTicketPrefix(x.upper()))\n",
    "df_test['TicketNumber'] = df_test['Ticket'].apply(lambda x: getTicketNumber(x.upper()))\n",
    "df_test['TicketFirstDigit'] = df_test['TicketNumber'].apply(lambda x: str(x)[0]).astype(np.int)\n",
    "df_test['TicketNumDigits'] = df_test['TicketNumber'].apply(lambda x: len(str(x))).astype(np.int)\n",
    "\n",
    "# Process ticket creating same categories for train and test. Otherwise, we will be getting different columns\n",
    "train_categories = df_train['TicketPrefix'].astype('category').cat.categories.tolist()\n",
    "test_categories = df_test['TicketPrefix'].astype('category').cat.categories.tolist()\n",
    "ticket_categories = list(set().union(train_categories,test_categories))\n",
    "\n",
    "print ticket_categories\n",
    "# Set TicketPrefix feature as categorical, using the previous list\n",
    "df_train['TicketPrefix'] = df_train['TicketPrefix'].astype('category', categories=ticket_categories)\n",
    "df_test['TicketPrefix'] = df_test['TicketPrefix'].astype('category', categories=ticket_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"FE2_sibsp\"></a>\n",
    "## 5.6.  Playing with:  'SibSp' and 'Parch'\n",
    "* SibSp (Number of Siblings/Spouses Aboard) and Parch (Number of Parents/Children Aboard) could be merged into one feature: 'FamilySize'\n",
    "* Create variable 'Alone' (or without family), as derivate of SibSp and Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create 'FamilySize' feature\n",
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1 \n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1 \n",
    "\n",
    "# Create boolean 'Alone' feature\n",
    "df_train['Alone'] = df_train.apply(lambda x: 1 if (x['FamilySize']==1) \n",
    "                                   else 0, axis=1)\n",
    "df_test['Alone'] = df_test.apply(lambda x: 1 if (x['FamilySize']==1) \n",
    "                                   else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Prediction_models_2\"></a>\n",
    "# 6. Prediction models (II) - After more feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TODO ** Make graph to see the importance of each variable for a model\n",
    "* We will scale the variables. Although Random Forest and decision trees in general are not affected by unnormalised variables, other mother may be affected. \n",
    "    * This made a large improvement on the accuracy, for certain models, such as SVM\n",
    "* Ticket dummies do not seem to improve the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a clean data frame for the regression\n",
    "\n",
    "# Columns to keep\n",
    "cols_to_keep = ['AgeFill', 'SibSp', 'Parch', 'FareFill', 'FamilySize', 'Alone']\n",
    "#cols_to_keep = ['AgeFill', 'SibSp', 'Parch', 'FareFill', 'FamilySize', 'Alone', 'TicketFirstDigit', 'TicketNumDigits']\n",
    "##cols_to_drop = ['TicketPrefix', 'TicketNumber', 'TicketFirstDigit', 'TicketNumDigits']\n",
    "\n",
    "# Replace categorical variables by dummy variables\n",
    "#cols_dummy = ['Sex', 'Embarked', 'Pclass', 'Title']\n",
    "cols_dummy = ['Sex', 'Embarked', 'Pclass', 'Title', 'Person']\n",
    "#cols_dummy = ['Sex', 'Embarked', 'Pclass', 'Title', 'Person', 'TicketPrefix'] # Worse accuracy\n",
    "\n",
    "# Training set\n",
    "X_train = df_train[cols_to_keep].join(\n",
    "    pd.get_dummies(df_train[cols_dummy], prefix=cols_dummy, columns=cols_dummy))\n",
    "\n",
    "# Target\n",
    "Y_train = df_train['Survived']\n",
    "\n",
    "# Test set\n",
    "X_test = df_test[cols_to_keep].join(\n",
    "    pd.get_dummies(df_test[cols_dummy], prefix=cols_dummy, columns=cols_dummy))\n",
    "\n",
    "# Scale features\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Score-CV</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.849607</td>\n",
       "      <td>0.831698</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.830568</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.826105</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.809231</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KN-3</td>\n",
       "      <td>0.882155</td>\n",
       "      <td>0.801435</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GNB</td>\n",
       "      <td>0.805836</td>\n",
       "      <td>0.800249</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.796846</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.779986</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.768799</td>\n",
       "      <td>0.686169</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model     Score  Score-CV  \\\n",
       "1            SVC  0.849607  0.831698   \n",
       "8        XGBoost  0.876543  0.830568   \n",
       "0             LR  0.833895  0.826105   \n",
       "7  Random Forest  0.984287  0.809231   \n",
       "2           KN-3  0.882155  0.801435   \n",
       "4            GNB  0.805836  0.800249   \n",
       "3             DT  0.984287  0.796846   \n",
       "6            SGD  0.494949  0.779986   \n",
       "5     Perceptron  0.768799  0.686169   \n",
       "\n",
       "                                          Prediction  \n",
       "1  [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "8  [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "0  [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "7  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "4  [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "3  [0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "6  [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, ...  \n",
       "5  [0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results = get_scores(model_list, X_train_std, Y_train, X_test_std)\n",
    "df_model_results = print_scores(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837278401998\n"
     ]
    }
   ],
   "source": [
    "# Voting system\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "selected_models = [{'function': LogisticRegression(), 'name': 'LR'},\n",
    "    {'function': SVC(), 'name': 'SVC'},\n",
    "    {'function': KNeighborsClassifier(n_neighbors = 3), 'name': 'KN-3'},\n",
    "    {'function': RandomForestClassifier(n_estimators=100), 'name': 'Random Forest'},\n",
    "    {'function': XGBClassifier(), 'name': 'XGBoost'}\n",
    "]\n",
    "seed=7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "for m in selected_models:\n",
    "    estimators.append((m['name'],m['function']))\n",
    "    \n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X_train_std, Y_train, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ensemble.fit(X_train_std, Y_train)\n",
    "Y_pred = clf.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take model with best score\n",
    "#Y_pred = df_model_results.sort_values(by='Score-CV', ascending=False).iloc[0]['Prediction']\n",
    "filename='submission_ensemble.csv'\n",
    "create_submission_from_list(Y_pred, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Feature_selection\"></a>\n",
    "# 7. Feature Selection\n",
    "* We may have too many features. We'll try to simplify our models to see if we can get more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
    "fit = model.fit(X_train,Y_train)\n",
    "score_cv_before, Y_pred = compute_model_score_cv(model, X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get importance for each feature\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = X_train.columns\n",
    "features['importance'] = fit.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "#features.set_index('feature', inplace=True)\n",
    "features = features.reset_index(drop=True)\n",
    "\n",
    "# Plot feature importances\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.barplot(ax=ax, data=features, y='feature', x='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select features using sklearn's SelectFromModel()\n",
    "model_reduced = SelectFromModel(fit, prefit=True)\n",
    "X_train_reduced = model_reduced.transform(X_train)\n",
    "print 'X_train reduced from ' + str(X_train.shape) + ' to ' + str(X_train_reduced.shape)\n",
    "\n",
    "model_reduced = SelectFromModel(fit, prefit=True)\n",
    "X_test_reduced = model_reduced.transform(X_test)\n",
    "print 'X_test reduced from ' + str(X_test.shape) + ' to ' + str(X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try Random Forest again with the reduced list of features\n",
    "model = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n",
    "score_cv_after, Y_pred = compute_model_score_cv(model, X_train_reduced, Y_train, X_test_reduced)\n",
    "\n",
    "print 'Score before: ' + str(score_cv_before)\n",
    "print 'Score after: ' + str(score_cv_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_results = []\n",
    "# Scale features\n",
    "sc = StandardScaler()\n",
    "X_train_reduced_ = sc.fit_transform(X_train_reduced)\n",
    "X_test_reduced_ = sc.transform(X_test_reduced)\n",
    "\n",
    "model_results = get_scores(model_list, X_train_reduced_, Y_train, X_test_reduced_)\n",
    "df_model_results = print_scores(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Model_tuning\"></a>\n",
    "# 8. Model tuning\n",
    "* Let's tune Random Forest (We'll take as reference scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Tuning Random Foreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train_reduced, Y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_parameters = random_search.best_params_\n",
    "best_parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n",
    "                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n",
    "#model = RandomForestClassifier(n_estimators=100, **best_parameters)\n",
    "model = RandomForestClassifier(**best_parameters)\n",
    "score_cv, Y_pred = compute_model_score_cv(model, X_train_reduced, Y_train, X_test_reduced)\n",
    "print score_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean validation score: 0.840 (std: 0.021)\n",
    "Parameters: {'bootstrap': True, 'min_samples_leaf': 4, 'min_samples_split': 4, 'criterion': 'entropy', 'max_features': 7, 'max_depth': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Tuning SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "              'degree': sp_randint(2,6),\n",
    "              'probability': [True, False],\n",
    "              'shrinking': [True, False],\n",
    "              'class_weight':['balanced', None],\n",
    "              'gamma': scipy.stats.expon(scale=.1),\n",
    "              'C': scipy.stats.expon(scale=100)\n",
    "             }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "start = time()\n",
    "random_search.fit(X_train_reduced, Y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Model_evaluation\"></a>\n",
    "# 9. Model evaluation\n",
    "We evaluate the chosen model visualising the learning curve for bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Function taken from the manual http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.gca().invert_yaxis() ## Invert plot to hint error (1 - score)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAEWCAYAAACt0rvRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8432c12390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters ={'bootstrap': True, 'min_samples_leaf': 4, 'min_samples_split': 4, 'criterion': 'entropy', 'max_features': 7, 'max_depth': None}\n",
    "model = RandomForestClassifier(**parameters)\n",
    "model2 = RandomForestClassifier()\n",
    "model2 = SVC()\n",
    "plot_learning_curve(model2, \"Learning Curve (RF)\", X_train_std, Y_train, ylim=(0.7, 1.01), cv=10, n_jobs=2)\n",
    "#train_sizes, train_scores, valid_scores = learning_curve(\n",
    "#    model, X_train, Y_train, cv=10, n_jobs=2, train_sizes=np.linspace(.1, 1., 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"Save_predictions\"></a>\n",
    "# Save predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose model and save its prediction\n",
    "# Take model with best score\n",
    "Y_pred = df_model_results.sort_values(by='Score-CV', ascending=False).iloc[0]['Prediction']\n",
    "filename='submission_SVC.csv'\n",
    "create_submission_from_list(Y_pred, filename)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
